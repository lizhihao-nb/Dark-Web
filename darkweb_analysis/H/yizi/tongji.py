import pandas as pd
import numpy as np
import glob
import os

# ====== é…ç½®ç›®å½•è·¯å¾„ ======
data_dir = "/public/home/blockchain_2/slave1/darkanalysis/analysis/yizi/"  # â† æŒ‰éœ€ä¿®æ”¹
# =========================

# å®šä¹‰å¼‚è´¨æ€§åŒºé—´
bins = [0.0, 0.5, 1.0, 2.0, 5.0, np.inf]
labels = ['[0.0, 0.5)', '[0.5, 1.0)', '[1.0, 2.0)', '[2.0, 5.0)', 'â‰¥5.0']

# æŸ¥æ‰¾æ‰€æœ‰ CSV æ–‡ä»¶
csv_files = sorted(glob.glob(os.path.join(data_dir, "*.csv")))
print(f"ğŸ“ å…±æ‰¾åˆ° {len(csv_files)} ä¸ª CSV æ–‡ä»¶ï¼š")
for f in csv_files:
    print(f"  - {os.path.basename(f)}")

# æ±‡æ€»ç»Ÿè®¡ç»“æœ
all_results = []

for csv_file in csv_files:
    try:
        df = pd.read_csv(csv_file)
        
        # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
        if 'Heterogeneity' not in df.columns or 'NodeCount' not in df.columns:
            print(f"âš ï¸  è·³è¿‡ {os.path.basename(csv_file)}ï¼šç¼ºå°‘ Heterogeneity æˆ– NodeCount åˆ—")
            continue
        
        # ä¸¢å¼ƒç¼ºå¤±å€¼
        valid_df = df[['Heterogeneity', 'NodeCount']].dropna()
        total_components = len(valid_df)
        total_nodes = valid_df['NodeCount'].sum()
        
        if total_components == 0:
            print(f"âš ï¸  è·³è¿‡ {os.path.basename(csv_file)}ï¼šæ— æœ‰æ•ˆ Heterogeneity/NodeCount æ•°æ®")
            continue
        
        # æŒ‰å¼‚è´¨æ€§åˆ†ç®±
        valid_df['H_bin'] = pd.cut(valid_df['Heterogeneity'], bins=bins, labels=labels, right=False)
        
        # æŒ‰åŒºé—´ç»Ÿè®¡ï¼šåˆ†é‡æ•°é‡ + èŠ‚ç‚¹æ€»æ•°
        group_stats = valid_df.groupby('H_bin').agg(
            component_count=('Heterogeneity', 'count'),
            total_node_count=('NodeCount', 'sum')
        ).reindex(labels, fill_value=0)  # ç¡®ä¿æ‰€æœ‰åŒºé—´éƒ½å­˜åœ¨
        
        # æ„å»ºç»“æœè¡Œ
        row = {'Filename': os.path.basename(csv_file)}
        for label in labels:
            comp_count = group_stats.loc[label, 'component_count']
            node_sum = int(group_stats.loc[label, 'total_node_count'])  # è½¬ä¸ºæ•´æ•°æ›´æ˜“è¯»
            comp_pct = round(comp_count / total_components * 100, 2) if total_components > 0 else 0.0
            
            row[f"{label}_comp%"] = comp_pct
            row[f"{label}_nodes"] = node_sum
        
        all_results.append(row)
        print(f"âœ… {os.path.basename(csv_file)}: {total_components} ä¸ªåˆ†é‡, æ€»èŠ‚ç‚¹æ•° {int(total_nodes)}")
    
    except Exception as e:
        print(f"âŒ å¤„ç† {os.path.basename(csv_file)} æ—¶å‡ºé”™: {e}")

# ç”Ÿæˆæ±‡æ€»è¡¨æ ¼
if all_results:
    summary_df = pd.DataFrame(all_results)
    
    # ä¿å­˜æ±‡æ€» CSV
    output_file = os.path.join(data_dir, "H_distribution_summary_with_nodes.csv")
    summary_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… æ±‡æ€»å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³:\n   {output_file}")
    print("\nğŸ“Š æ±‡æ€»é¢„è§ˆï¼ˆå‰5è¡Œï¼‰:")
    print(summary_df.head().to_string(index=False))
    
    # å¯é€‰ï¼šæ‰“å°åˆ—åç»“æ„è¯´æ˜
    print("\nğŸ“Œ è¾“å‡ºåˆ—è¯´æ˜:")
    print("   - Filename: CSV æ–‡ä»¶å")
    print("   - [åŒºé—´]_comp%: è¯¥å¼‚è´¨æ€§åŒºé—´å†…è¿é€šåˆ†é‡æ•°é‡å æ€»åˆ†é‡æ•°çš„ç™¾åˆ†æ¯”")
    print("   - [åŒºé—´]_nodes: è¯¥å¼‚è´¨æ€§åŒºé—´å†…æ‰€æœ‰è¿é€šåˆ†é‡çš„èŠ‚ç‚¹æ€»æ•°ï¼ˆç»å¯¹å€¼ï¼‰")
else:
    print("âŒ æœªæˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶")